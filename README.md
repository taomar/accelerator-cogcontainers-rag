# üß† AI-Powered RAG System üîç  
**Deployable Offline | On-Premise | Any Cloud**  

This project showcases a **Retrieval-Augmented Generation (RAG) system** designed for **flexibility, scalability, and real-world deployment**. 

Powered by **Azure AI Containers**, it ensures **high-performance retrieval, accuracy, and security**‚Äîwhether running **fully offline, or in any cloud environment**.

## **Why This Matters?**

**Hybrid Retrieval**: Combines **Qdrant (vector search)**, **BM25 (keyword matching)**, and **Ollama embeddings** to enhance ranking and accuracy.  

**Multilingual AI**: Supports **Arabic & English** with optimized retrieval for short queries and complex prompts.  

**Azure AI Integration**: Leverages **Azure AI Containers** for ensuring **better accuracy, security, and usability**‚Äîeven in offline environments.  

**On-Premise Ready**: Designed for **full offline deployment**, making it ideal for **customers needing secure, cloud-independent AI solutions**.  

---

## üîπ How Azure AI Containers Can Enhance your Offline RAG System
Azure AI Containers enable advanced AI capabilities while keeping the system **fully offline and on-premise-ready**. These services improve **document processing, query understanding, and response generation**, making the system **more accurate, secure, and scalable**.

| **Category**                          | **Azure AI Service**                                  | **Enhancement** |
|--------------------------------------|-----------------------------------------------------|----------------|
| **üìÑ Improving Document Processing & Indexing** | **Azure AI Vision - Read** | Extracts text from **scanned documents & images**, making PDFs and handwritten content searchable. |
|                                      | **Azure Document Intelligence** | Processes **structured documents** (e.g., invoices, contracts) before indexing, improving retrieval in legal and enterprise use cases. |
| **üîé Enhancing Query Understanding & Retrieval** | **Azure AI Language** | Detects **query language** to route requests correctly. |
|                                      | **Conversational Language Understanding (CLU)** | Classifies **query intent** (e.g., search vs. summarization) for smarter responses. |
| **ü§ñ Enhancing AI-Generated Responses** | **Azure AI Sentiment Analysis** | Adjusts AI response **tone** (formal/casual) based on sentiment detection. |
|                                      | **Azure AI Text Translation** | Enables **cross-language retrieval** (e.g., Arabic query ‚Üí English documents). |
|                                      | **Neural Text-to-Speech (TTS)** | Converts **AI responses into speech**, enabling chatbot and voice assistant integrations. |
| **üõ°Ô∏è Ensuring Content Safety & Compliance** | **Azure AI Content Safety** | Scans **both text and images** for **violence, hate speech, self-harm, and explicit content**, ensuring AI-generated responses and retrieved documents comply with safety standards. |

üîπ **These integrations ensure the RAG system remains fully functional in offline environments while benefiting from enterprise-grade AI.**  

üìå **Learn More**: [Azure AI Containers](https://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-container-support)  
üìå **Azure AI Content Safety**: [Content Safety Containers (Preview)](https://learn.microsoft.com/en-us/azure/ai-services/content-safety/how-to/containers/container-overview)  

---

## ‚úÖ Enhanced User Flow with Azure AI Containers

| **Step** | **Tool Used** | **Description** |
|----------|-------------|----------------|
| **1. User enters or speaks a query** | Streamlit UI + **Azure AI Speech (Offline Container)** | Users can either type or speak their query. |
| **2. Spellcheck query** | **Bergamot (Local Spellchecker)** | Fixes typos before processing the query. |
| **3. Detect query language** | **Azure AI Language (Offline Container)** | Determines whether the query is in Arabic or English. |
| **4. Translate query (if needed)** | **Azure Translator (Optional)** | Converts non-Arabic/English queries into a supported language. |
| **5. Generate query embedding** | **Ollama (`bge-m3` for English & Arabic)** | Converts the query into a numerical vector representation. |
| **6. Retrieve relevant documents** | **Qdrant (Vector DB) + BM25 Hybrid Retrieval** | Performs a **hybrid search**: vector similarity search (embeddings) + keyword-based retrieval (BM25). |
| **7. Rank retrieved documents** | **BM25 (Rank-BM25) + `bge-m3` Reranking** | Ranks results based on **keyword relevance and vector similarity**. |
| **8. Extract named entities (Optional)** | **Azure AI NER (Offline Container)** | Identifies **key entities** in the query to improve retrieval precision. |
| **9. Apply OCR for document parsing** | **Azure Document Intelligence (Offline Container)** | Extracts text from **scanned PDFs, images, or structured documents** to improve knowledge base ingestion. |
| **10. Summarize long documents (Optional)** | **Azure Text Summarization (Offline Container)** | Summarizes **retrieved long documents** before passing them to the LLM. |
| **11. Generate an AI response** | **Ollama (`Qwen2.5` for English & `Gemma2B` for Arabic)** | Uses an **LLM** to generate an **answer using the top-ranked documents as context**. |
| **12. Apply content safety filters** | **Azure AI Content Safety (Offline Container)** | Ensures the **AI-generated response follows safety guidelines**, filtering out harmful or inappropriate content. |
| **13. Display response** | **Streamlit UI** | Shows **retrieved documents, scores, and the final AI response**. |

---
## üõ†Ô∏è **Setup & Installation**  

### **1Ô∏è‚É£ Preinstalled Requirements**
Ensure you have the following installed before proceeding:
- **Python 3.9+** ‚Üí [Download Here](https://www.python.org/downloads/)
- **Docker** ‚Üí [Download Here](https://www.docker.com/get-started/)
- **Ollama** ‚Üí [Install Guide](https://ollama.com)

### **1Ô∏è‚É£ Clone the Repository**
```bash
git clone https://github.com/hamzaelgh/edge-rag.git
cd edge-rag
```

### **2Ô∏è‚É£ Set Up Python Virtual Environment**
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate   # Windows
```

### **3Ô∏è‚É£ Install Dependencies**
```bash
pip install -r requirements.txt
source .env 
```

### **4Ô∏è‚É£ Start Qdrant (Vector Database)**
Make sure **Docker** is installed, then run:
```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

### **5Ô∏è‚É£ Install & Run Ollama**
Follow Ollama installation from [Ollama's official website](https://ollama.com). Then, pull the required models:
```bash
ollama serve 
ollama pull qwen2.5:0.5b
ollama pull gemma2:2b
ollama pull bge-m3
ollama pull jaluma/arabert-all-nli-triplet-matryoshka:latest 
```

### **6Ô∏è‚É£ Run Azure AI Containers for Language Detection**
#### **Language Detection**
```bash
docker run --rm -it --platform linux/amd64 -p 5000:5000 --memory 6g --cpus 2 \
  mcr.microsoft.com/azure-cognitive-services/textanalytics/language \
  Eula=accept \
  Billing="$AZURE_LANGUAGE_BILLING_URL" \
  ApiKey="$AZURE_LANGUAGE_API_KEY"
```

```
curl -X POST "http://localhost:5000/text/analytics/v3.1/languages" \
     -H "Content-Type: application/json" \
     -d '{
          "documents": [
            {"id": "1", "text": "Hello, how are you?"},
            {"id": "2", "text": "ŸÖÿ±ÿ≠ÿ®ÿß ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉÿü"}
          ]
        }'
```

### **7Ô∏è‚É£ Prepare & Index Documents**
Store your dataset inside the `data/` folder, then run:
```bash
python src/indexer.py
```

Verify if the Qdrant Collections Exist
```
curl -X GET "http://localhost:6333/collections"
```

Clean Qdrant Collections if needed. 
```
curl -X DELETE "http://localhost:6333/collections/rag_docs_en"
curl -X DELETE "http://localhost:6333/collections/rag_docs_ar"
```

## ** Testing the System 

```
PYTHONPATH=$(pwd) pytest tests/test_indexer.py # Test Indexing & Qdrant Setup

PYTHONPATH=$(pwd) pytest tests/test_retriever.py # Test Document Retrieval & Search

PYTHONPATH=$(pwd) pytest tests/test_ai_responses.py # Test AI Response Generation 

PYTHONPATH=$(pwd) python tests/test_retriever_queries.py # Output: Retrieved documents, Detected query language & Relevance scores

PYTHONPATH=$(pwd) python tests/test_ai_responses.py # Test AI Response with Context. This will test if the AI correctly generates responses based on retrieved documents.
```


### **8Ô∏è‚É£ Start the Streamlit UI**
```bash
streamlit run src/app.py
```



### **9Ô∏è‚É£ Test Queries**
Open your browser at `http://localhost:8501` and enter any query.  
Examples:  
- **English:** `"What is artificial intelligence?"`  
- **Arabic:** `"ŸÖÿß ŸáŸà ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸäÿü"`

---
## üìå **Addressing Arabic Language Challenges**

1Ô∏è‚É£ Challenge: Arabic Ranker Models**

**Problem:** Many ranker models struggle to reconstruct answers when the supporting information is scattered across multiple chunks.  
**Solution:** We integrate **BM25 + bge-m3 reranker**, which improves the ranking of relevant Arabic documents based on **semantic similarity and keyword matching**.

2Ô∏è‚É£ Challenge: Arabic Embedding Models**

**Problem:** Single-word Arabic queries sometimes fail to retrieve results, even when relevant content exists in the knowledge base.  
**Solution:** We use a **hybrid search approach**, combining:
   - **Vector search (Ollama embeddings)**
   - **BM25 keyword matching**
   - **Reranking using bge-m3**
   This ensures better retrieval even for **short Arabic queries**.


3Ô∏è‚É£ Mitigating those Issues** 

Our current implementation mitigates these issues with:
  - Hybrid Search (BM25 + Vectors)
  - Re-ranking (bge-m3)
  - Named Entity Recognition (NER)
  - LLM Context Expansion

4Ô∏è‚É£ Future Improvements
-  **Experiment with specialized Arabic embedding models** (e.g., Arabic-trained versions of BGE or ARABERT).  
-  **Optimize BM25 weights for Arabic vs. English separately** to fine-tune ranking balance.  
-  **Extend Named Entity Recognition (NER) to improve keyword-based lookup**.  
-  **Benchmark different Arabic language models for better retrieval performance**.

---
Enjoy building your **production-ready RAG system**! üèóÔ∏èüî•  