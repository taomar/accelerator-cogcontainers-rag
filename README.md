# ğŸ§  AI-Powered RAG System: Deployable Offline, On-Premise, or Any Cloud ğŸš€  

This repository demonstrates how to build a **Retrieval-Augmented Generation (RAG) system** that is **cloud-agnostic, fully deployable offline, on-premise, or on any cloud**.

The system integrates **Ollama, Qdrant, BM25, and embeddings**, with **multilingual support (Arabic & English)** and **fine-tuned retrieval enhancements** to improve accuracy and ranking.  

Integrating **Azure AI Containers** enhances the **accuracy, security, and usability** of the system while keeping it **offline and on-premise compatible**.  

âš¡ **This can help you build a PoC on Azure to assist a customer in deploying a RAG solution on-premise using Azure AI containers.**  
ğŸ“Œ More details: [Azure AI Containers](https://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-container-support)  


---

## ğŸ— Enhanced User Flow with Azure AI Containers  

| **Step**                     | **Tool Used**                 | **Description** |
|------------------------------|------------------------------|----------------|
| **1. User enters a query**    | Streamlit UI                 | Provides an input field for users to enter queries. |
| **2. Detect query language**  | **Azure AI Language (Offline Container)**  | Determines whether the query is in Arabic or English. |
| **3. Generate query embedding** | Ollama (`bge-m3`) | Converts the query into a numerical vector representation. |
| **4. Retrieve relevant documents** | Qdrant (Vector DB)       | Performs a **hybrid search**: **vector similarity search** (embeddings) + **BM25 keyword match**. |
| **5. Rank retrieved documents** | BM25 (Rank-BM25) + `bge-m3`  | Ranks results based on keyword relevance and vector similarity. |
| **6. Extract named entities (Optional)** | **Azure AI NER (Offline Container)** | Identifies key entities in the query to improve retrieval precision. |
| **7. Apply OCR for document parsing** | **Azure Document Intelligence (Offline Container)** | Extracts text from scanned PDFs, images, or structured documents to improve knowledge base ingestion. |
| **8. Generate an AI response** | Ollama (`Qwen/Gemma`) | Uses an **LLM to generate an answer** using the top-ranked documents as context. |
| **9. Apply content safety filters** | **Azure AI Content Safety (Offline Container)** | Ensures the **AI-generated response follows safety guidelines**, filtering out harmful or inappropriate content. |
| **10. Display response**       | Streamlit UI                 | Shows retrieved documents, scores, and final AI response. |

---

## ğŸš€ How Azure AI Containers Improve the System  

### âœ… **Azure AI Language Container**  
- Ensures **accurate language detection** for Arabic & English queries.  
- Helps select the correct **embedding model & retrieval method**.  

### âœ… **Azure AI Named Entity Recognition (NER) Container (Optional)**  
- Extracts **key entities from queries** to **enhance search precision**.  
- Improves **retrieval for specific industry-related queries** (e.g., oil & gas terms).  

### âœ… **Azure Document Intelligence Container**  
- Enables **OCR-based text extraction** from **PDFs, scanned reports, and images**.  
- Improves **knowledge base ingestion**, allowing **structured & unstructured** data retrieval.  

### âœ… **Azure AI Content Safety Container**  
- Ensures **AI-generated responses do not include harmful, biased, or sensitive content**.  
- Helps meet compliance & safety standards for **enterprise use cases**.  

---
## ğŸ› ï¸ **Setup & Installation**  

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo/edge-rag.git
cd edge-rag
```

### **2ï¸âƒ£ Set Up Python Virtual Environment**
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate   # Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Start Qdrant (Vector Database)**
Make sure **Docker** is installed, then run:
```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

### **5ï¸âƒ£ Install & Run Ollama**
Follow Ollama installation from [Ollama's official website](https://ollama.com). Then, pull the required models:
```bash
ollama serve 
ollama pull qwen2.5:0.5b
ollama pull gemma2:2b
ollama pull bge-m3
```

### **6ï¸âƒ£ Run Azure AI Containers for Language Detection & NER**
#### **Language Detection**
```bash
docker run --rm -it --platform linux/amd64 -p 5000:5000 --memory 6g --cpus 2 \
  mcr.microsoft.com/azure-cognitive-services/textanalytics/language \
  Eula=accept \
  Billing="$AZURE_LANGUAGE_BILLING_URL" \
  ApiKey="$AZURE_LANGUAGE_API_KEY"
```

```
curl -X POST "http://localhost:5000/text/analytics/v3.1/languages" \
     -H "Content-Type: application/json" \
     -d '{
          "documents": [
            {"id": "1", "text": "Hello, how are you?"},
            {"id": "2", "text": "Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ"}
          ]
        }'
```

### **7ï¸âƒ£ Prepare & Index Documents**
Store your dataset inside the `data/` folder, then run:
```bash
python src/index_documents.py
```

Verify if the Qdrant Collections Exist
```
curl -X GET "http://localhost:6333/collections"
```

### **8ï¸âƒ£ Start the Streamlit UI**
```bash
streamlit run src/streamlit_app.py
```

### **9ï¸âƒ£ Test Queries**
Open your browser at `http://localhost:8501` and enter any query.  
Examples:  
- **English:** `"What is artificial intelligence?"`  
- **Arabic:** `"Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŸ"`

The system will:
1. **Detect query language using Azure AI**
2. **Perform Named Entity Recognition (NER)**
3. **Retrieve relevant documents from Qdrant**
4. **Rank results using BM25 + embedding similarity + reranking**
5. **Generate an AI response using Ollama**

---

## ğŸ“Œ **Addressing Arabic Language Challenges**

- 1ï¸âƒ£ Challenge: Arabic Ranker Models**

ğŸ“Œ **Problem:** Many ranker models struggle to reconstruct answers when the supporting information is scattered across multiple chunks.  
âœ… **Solution:** We integrate **BM25 + bge-m3 reranker**, which improves the ranking of relevant Arabic documents based on **semantic similarity and keyword matching**.

-  2ï¸âƒ£ Challenge: Arabic Embedding Models**

ğŸ“Œ **Problem:** Single-word Arabic queries sometimes fail to retrieve results, even when relevant content exists in the knowledge base.  
âœ… **Solution:** We use a **hybrid search approach**, combining:
   - **Vector search (Ollama embeddings)**
   - **BM25 keyword matching**
   - **Reranking using bge-m3**
   This ensures better retrieval even for **short Arabic queries**.


- 3ï¸âƒ£ Mitigating those Issues** 

ğŸ“Œ Our current implementation mitigates these issues with:
  - Hybrid Search (BM25 + Vectors)
  - Re-ranking (bge-m3)
  - Named Entity Recognition (NER)
  - LLM Context Expansion

- 4ï¸âƒ£ Future Improvements

ğŸŸ¢ **Experiment with specialized Arabic embedding models** (e.g., Arabic-trained versions of BGE or MARBERT).  
ğŸŸ¢ **Optimize BM25 weights for Arabic vs. English separately** to fine-tune ranking balance.  
ğŸŸ¢ **Extend Named Entity Recognition (NER) to improve keyword-based lookup**.  
ğŸŸ¢ **Benchmark different Arabic language models for better retrieval performance**.

---

This system is designed to be **fully deployable offline, on-premise, or in any cloud** with **optimized Arabic & English retrieval**. ğŸš€  

Enjoy building your **production-ready RAG system**! ğŸ—ï¸ğŸ”¥  
